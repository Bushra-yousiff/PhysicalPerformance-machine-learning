{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "4fb319e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84563e66",
   "metadata": {},
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "bc6e8eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>body fat_%</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>systolic</th>\n",
       "      <th>gripForce</th>\n",
       "      <th>sit and bend forward_cm</th>\n",
       "      <th>sit-ups counts</th>\n",
       "      <th>broad jump_cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>M</td>\n",
       "      <td>172.3</td>\n",
       "      <td>75.24</td>\n",
       "      <td>21.3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>54.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>M</td>\n",
       "      <td>165.0</td>\n",
       "      <td>55.80</td>\n",
       "      <td>15.7</td>\n",
       "      <td>77.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>M</td>\n",
       "      <td>179.6</td>\n",
       "      <td>78.00</td>\n",
       "      <td>20.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>44.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>174.5</td>\n",
       "      <td>71.10</td>\n",
       "      <td>18.4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>41.4</td>\n",
       "      <td>15.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>M</td>\n",
       "      <td>173.8</td>\n",
       "      <td>67.70</td>\n",
       "      <td>17.1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>27.1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13388</th>\n",
       "      <td>25.0</td>\n",
       "      <td>M</td>\n",
       "      <td>172.1</td>\n",
       "      <td>71.80</td>\n",
       "      <td>16.2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13389</th>\n",
       "      <td>21.0</td>\n",
       "      <td>M</td>\n",
       "      <td>179.7</td>\n",
       "      <td>63.90</td>\n",
       "      <td>12.1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13390</th>\n",
       "      <td>39.0</td>\n",
       "      <td>M</td>\n",
       "      <td>177.2</td>\n",
       "      <td>80.50</td>\n",
       "      <td>20.1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>63.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13391</th>\n",
       "      <td>64.0</td>\n",
       "      <td>F</td>\n",
       "      <td>146.1</td>\n",
       "      <td>57.70</td>\n",
       "      <td>40.4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13392</th>\n",
       "      <td>34.0</td>\n",
       "      <td>M</td>\n",
       "      <td>164.0</td>\n",
       "      <td>66.10</td>\n",
       "      <td>19.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13393 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age gender  height_cm  weight_kg  body fat_%  diastolic  systolic  \\\n",
       "0      27.0      M      172.3      75.24        21.3       80.0     130.0   \n",
       "1      25.0      M      165.0      55.80        15.7       77.0     126.0   \n",
       "2      31.0      M      179.6      78.00        20.1       92.0     152.0   \n",
       "3      32.0      M      174.5      71.10        18.4       76.0     147.0   \n",
       "4      28.0      M      173.8      67.70        17.1       70.0     127.0   \n",
       "...     ...    ...        ...        ...         ...        ...       ...   \n",
       "13388  25.0      M      172.1      71.80        16.2       74.0     141.0   \n",
       "13389  21.0      M      179.7      63.90        12.1       74.0     128.0   \n",
       "13390  39.0      M      177.2      80.50        20.1       78.0     132.0   \n",
       "13391  64.0      F      146.1      57.70        40.4       68.0     121.0   \n",
       "13392  34.0      M      164.0      66.10        19.5       82.0     150.0   \n",
       "\n",
       "       gripForce  sit and bend forward_cm  sit-ups counts  broad jump_cm class  \n",
       "0           54.9                     18.4            60.0          217.0     C  \n",
       "1           36.4                     16.3            53.0          229.0     A  \n",
       "2           44.8                     12.0            49.0          181.0     C  \n",
       "3           41.4                     15.2            53.0          219.0     B  \n",
       "4           43.5                     27.1            45.0          217.0     B  \n",
       "...          ...                      ...             ...            ...   ...  \n",
       "13388       35.8                     17.4            47.0          198.0     C  \n",
       "13389       33.0                      1.1            48.0          167.0     D  \n",
       "13390       63.5                     16.4            45.0          229.0     A  \n",
       "13391       19.3                      9.2             0.0           75.0     D  \n",
       "13392       35.9                      7.1            51.0          180.0     C  \n",
       "\n",
       "[13393 rows x 12 columns]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bodyPerformance.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4989b37",
   "metadata": {},
   "source": [
    "## Quick one line EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df)\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6389343",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "42e6d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unreal entries and encoding the gender, class columns\n",
    "df.replace(\"M\", 0 , inplace = True)\n",
    "df.replace(\"F\", 1 , inplace = True)\n",
    "df.replace(\"A\", 0 , inplace = True)\n",
    "df.replace(\"B\", 1 , inplace = True)\n",
    "df.replace(\"C\", 2 , inplace = True)\n",
    "df.replace(\"D\", 3 , inplace = True)\n",
    "\n",
    "df = df[df['body fat_%'] > 6.4] \n",
    "df = df[df['diastolic'] > 60] \n",
    "df = df[df['systolic'] > 90] \n",
    "df = df[df['gripForce'] > 5]  \n",
    "df = df[df['sit-ups counts'] > 5] \n",
    "df = df[df['broad jump_cm'] > 80] \n",
    "df = df[df['sit and bend forward_cm'] > -20] \n",
    "df = df[df['sit and bend forward_cm'] < 25] \n",
    "#featrue engineering\n",
    "df['BMI'] = df['weight_kg'] / ((df['height_cm']/100)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "32a480bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>body fat_%</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>systolic</th>\n",
       "      <th>gripForce</th>\n",
       "      <th>sit and bend forward_cm</th>\n",
       "      <th>sit-ups counts</th>\n",
       "      <th>broad jump_cm</th>\n",
       "      <th>class</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "      <td>11444.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.897676</td>\n",
       "      <td>0.313002</td>\n",
       "      <td>169.248523</td>\n",
       "      <td>68.452125</td>\n",
       "      <td>23.010114</td>\n",
       "      <td>80.003906</td>\n",
       "      <td>131.512146</td>\n",
       "      <td>37.865191</td>\n",
       "      <td>14.118352</td>\n",
       "      <td>40.417022</td>\n",
       "      <td>192.859673</td>\n",
       "      <td>1.549021</td>\n",
       "      <td>23.770878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.528079</td>\n",
       "      <td>0.463736</td>\n",
       "      <td>8.253594</td>\n",
       "      <td>11.791394</td>\n",
       "      <td>7.010194</td>\n",
       "      <td>9.710371</td>\n",
       "      <td>14.066829</td>\n",
       "      <td>10.346623</td>\n",
       "      <td>7.393839</td>\n",
       "      <td>13.336014</td>\n",
       "      <td>37.587414</td>\n",
       "      <td>1.094803</td>\n",
       "      <td>2.894002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>-19.900000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.314973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>163.500000</td>\n",
       "      <td>59.700000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.846457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.639651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>175.100000</td>\n",
       "      <td>76.100000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>45.600000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.469097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>193.800000</td>\n",
       "      <td>138.100000</td>\n",
       "      <td>54.900000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>42.906509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        gender     height_cm     weight_kg    body fat_%  \\\n",
       "count  11444.000000  11444.000000  11444.000000  11444.000000  11444.000000   \n",
       "mean      36.897676      0.313002    169.248523     68.452125     23.010114   \n",
       "std       13.528079      0.463736      8.253594     11.791394      7.010194   \n",
       "min       21.000000      0.000000    125.000000     31.900000      6.500000   \n",
       "25%       25.000000      0.000000    163.500000     59.700000     17.900000   \n",
       "50%       33.000000      0.000000    170.000000     68.600000     22.600000   \n",
       "75%       48.000000      1.000000    175.100000     76.100000     27.600000   \n",
       "max       64.000000      1.000000    193.800000    138.100000     54.900000   \n",
       "\n",
       "          diastolic      systolic     gripForce  sit and bend forward_cm  \\\n",
       "count  11444.000000  11444.000000  11444.000000             11444.000000   \n",
       "mean      80.003906    131.512146     37.865191                14.118352   \n",
       "std        9.710371     14.066829     10.346623                 7.393839   \n",
       "min       61.000000     91.000000      5.300000               -19.900000   \n",
       "25%       73.000000    121.000000     28.800000                10.300000   \n",
       "50%       80.000000    131.000000     39.200000                15.500000   \n",
       "75%       87.000000    142.000000     45.600000                19.600000   \n",
       "max      126.000000    201.000000     70.500000                24.900000   \n",
       "\n",
       "       sit-ups counts  broad jump_cm         class           BMI  \n",
       "count    11444.000000   11444.000000  11444.000000  11444.000000  \n",
       "mean        40.417022     192.859673      1.549021     23.770878  \n",
       "std         13.336014      37.587414      1.094803      2.894002  \n",
       "min          6.000000      81.000000      0.000000     11.314973  \n",
       "25%         31.000000     165.000000      1.000000     21.846457  \n",
       "50%         42.000000     196.000000      2.000000     23.639651  \n",
       "75%         51.000000     222.000000      3.000000     25.469097  \n",
       "max         78.000000     303.000000      3.000000     42.906509  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "45ca78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split datafarme by class and gender:\n",
    "AM = df[(df['class'] == 0) & (df['gender'] == 0)]\n",
    "AF = df[(df['class'] == 0) & (df['gender'] == 1)]\n",
    "\n",
    "BM = df[(df['class'] == 1) & (df['gender'] == 0)]\n",
    "BF = df[(df['class'] == 1) & (df['gender'] == 1)]\n",
    "\n",
    "CM = df[(df['class'] == 2) & (df['gender'] == 0)]\n",
    "CF = df[(df['class'] == 2) & (df['gender'] == 1)]\n",
    "\n",
    "DM = df[(df['class'] == 3) & (df['gender'] == 0)]\n",
    "DF = df[(df['class'] == 3) & (df['gender'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "fbe0ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outlier from class A based on body fat_% and BMI\n",
    "\n",
    "lower_quantile , upper_quantile = AM['BMI'].quantile([0, .90])\n",
    "AM = AM.loc[(AM['BMI'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = AF['BMI'].quantile([0, .90])\n",
    "AF = AF.loc[(AF['BMI'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = AM['body fat_%'].quantile([0, .90])\n",
    "AM = AM.loc[(AM['body fat_%'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = AF['body fat_%'].quantile([0, .90])\n",
    "AF = AF.loc[(AF['body fat_%'] < upper_quantile)]\n",
    "\n",
    "a = [AM,AF]\n",
    "A = pd.concat(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "3af8c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outlier from class B based on body fat_% and BMI\n",
    "\n",
    "lower_quantile , upper_quantile = BM['BMI'].quantile([.15, .9])\n",
    "BM = BM.loc[(BM['BMI'] > lower_quantile) & (BM['BMI'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = BF['BMI'].quantile([.15, .9])\n",
    "BF = BF.loc[(BF['BMI'] > lower_quantile) & (BF['BMI'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = BM['body fat_%'].quantile([.15, .9])\n",
    "BM = BM.loc[(BM['body fat_%'] > lower_quantile) & (BM['body fat_%'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = BF['body fat_%'].quantile([.15, .9])\n",
    "BF = BF.loc[(BF['body fat_%'] > lower_quantile) & (BF['body fat_%'] < upper_quantile)]\n",
    "\n",
    "b = [BM,BF]\n",
    "B = pd.concat(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "27570a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outlier from class C based on body fat_% and BMI\n",
    "\n",
    "lower_quantile , upper_quantile = CM['BMI'].quantile([.15, .9])\n",
    "CM = CM.loc[(CM['BMI'] > lower_quantile) & (CM['BMI'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = CF['BMI'].quantile([.15, .9])\n",
    "CF = CF.loc[(CF['BMI'] > lower_quantile) & (CF['BMI'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = CM['body fat_%'].quantile([.15, .9])\n",
    "CM = CM.loc[(CM['body fat_%'] > lower_quantile) & (CM['body fat_%'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = CF['body fat_%'].quantile([.15, .9])\n",
    "CF = CF.loc[(CF['body fat_%'] > lower_quantile) & (CF['body fat_%'] < upper_quantile)]\n",
    "\n",
    "c = [CM,CF]\n",
    "C = pd.concat(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "7954d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outlier from class D based on body fat_% and BMI\n",
    "\n",
    "lower_quantile , upper_quantile = DM['BMI'].quantile([.2, 1])\n",
    "DM = DM.loc[(DM['BMI'] > lower_quantile) & (DM['BMI'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = DF['BMI'].quantile([.2, 1])\n",
    "DF = DF.loc[(DF['BMI'] > lower_quantile) & (DF['BMI'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = DM['body fat_%'].quantile([.2, 1])\n",
    "DM = DM.loc[(DM['body fat_%'] > lower_quantile) & (DM['body fat_%'] < upper_quantile)]\n",
    "\n",
    "lower_quantile , upper_quantile = DF['body fat_%'].quantile([.2, 1])\n",
    "DF = DF.loc[(DF['body fat_%'] > lower_quantile) & (DF['body fat_%'] < upper_quantile)]\n",
    "\n",
    "d = [DM,DF]\n",
    "D = pd.concat(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "b41c41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting everything back together\n",
    "Y= [A,B,C,D]\n",
    "final = pd.concat(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "a599177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the actual labels\n",
    "final['class'] = final['class'].replace(0,'A')\n",
    "final['class'] = final['class'].replace(1,'B')\n",
    "final['class'] = final['class'].replace(2,'C')\n",
    "final['class'] = final['class'].replace(3,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "b3e24f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight of class A is: 0.88\n",
      "weight of class B is: 1.1\n",
      "weight of class C is: 1.07\n",
      "weight of class D is: 0.98\n"
     ]
    }
   ],
   "source": [
    "#weights of each class:\n",
    "aweight = (final.gender.count())/(4*A.gender.count())\n",
    "bweight = (final.gender.count())/(4*B.gender.count())\n",
    "cweight = (final.gender.count())/(4*C.gender.count())\n",
    "dweight = (final.gender.count())/(4*D.gender.count())\n",
    "print(f'weight of class A is:', round(aweight,2))\n",
    "print(f'weight of class B is:', round(bweight,2))\n",
    "print(f'weight of class C is:', round(cweight,2))\n",
    "print(f'weight of class D is:', round(dweight,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "bd101c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7250 entries, 1 to 13374\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   age                      7250 non-null   float64\n",
      " 1   gender                   7250 non-null   int64  \n",
      " 2   height_cm                7250 non-null   float64\n",
      " 3   weight_kg                7250 non-null   float64\n",
      " 4   body fat_%               7250 non-null   float64\n",
      " 5   diastolic                7250 non-null   float64\n",
      " 6   systolic                 7250 non-null   float64\n",
      " 7   gripForce                7250 non-null   float64\n",
      " 8   sit and bend forward_cm  7250 non-null   float64\n",
      " 9   sit-ups counts           7250 non-null   float64\n",
      " 10  broad jump_cm            7250 non-null   float64\n",
      " 11  class                    7250 non-null   object \n",
      " 12  BMI                      7250 non-null   float64\n",
      "dtypes: float64(11), int64(1), object(1)\n",
      "memory usage: 793.0+ KB\n"
     ]
    }
   ],
   "source": [
    "final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca1d3d",
   "metadata": {},
   "source": [
    "## Spliting and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "92085b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = final.drop('class', axis = True)\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "final['class'] = final['class'].astype('category').cat.codes\n",
    "\n",
    "y = final['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d9676",
   "metadata": {},
   "source": [
    "## Function for modeling and confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "b84996f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_squared_error \n",
    "#dic to store model scores accuracy & MSE:\n",
    "score_values = {'Model Name':[],\n",
    "                'Accuracy score':[],\n",
    "                'MSE Before':[],\n",
    "                'After tuning':[],\n",
    "                'MSE After':[]}\n",
    "\n",
    "#A function for modeling\n",
    "def modeling(m, name, cm):\n",
    "    m.fit(X_train, y_train)\n",
    "    y_pred = m.predict(X_test)\n",
    "    s = accuracy_score(y_test, y_pred)\n",
    "    error = mean_squared_error(y_test, y_pred)\n",
    "    print(name ,'full classification report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    #if you want to show report and onfusion_matrix_heatmap\n",
    "    #cm -> Yes:show, No:skip\n",
    "    if 'after tuning' not in name:\n",
    "        score_values['Model Name'].append(name)\n",
    "        score_values['Accuracy score'].append(round(s, 5))\n",
    "        score_values['MSE Before'].append(error)\n",
    "    else:\n",
    "        score_values['After tuning'].append(round(s, 5))\n",
    "        score_values['MSE After'].append(error)\n",
    "    if cm == 'show':\n",
    "        x = confusion_matrix(y_test, y_pred)\n",
    "        fig = plt.figure(figsize=(15,7))\n",
    "        sns.heatmap(x/np.sum(x), annot = True, fmt=  '0.2%', cmap = 'Reds')\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d176a8a",
   "metadata": {},
   "source": [
    "## Experiment different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "abea98da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.83       429\n",
      "           1       0.51      0.41      0.46       335\n",
      "           2       0.59      0.65      0.62       317\n",
      "           3       0.94      0.91      0.92       369\n",
      "\n",
      "    accuracy                           0.73      1450\n",
      "   macro avg       0.71      0.71      0.71      1450\n",
      "weighted avg       0.72      0.73      0.72      1450\n",
      "\n",
      "Logistic Regression after tuning full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       429\n",
      "           1       0.52      0.48      0.50       335\n",
      "           2       0.60      0.67      0.63       317\n",
      "           3       0.94      0.91      0.93       369\n",
      "\n",
      "    accuracy                           0.74      1450\n",
      "   macro avg       0.72      0.72      0.72      1450\n",
      "weighted avg       0.74      0.74      0.74      1450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lg = LogisticRegression(random_state = 42)\n",
    "name1 = 'Logistic Regression'\n",
    "modeling(model_lg, name1, cm='skip')\n",
    "model_lg_tuned = LogisticRegression(class_weight = {0:0.9,1:1,2:1,3:1}, random_state = 42, multi_class = 'multinomial', solver = 'lbfgs', penalty = 'none')\n",
    "name2 = 'Logistic Regression after tuning'\n",
    "#if you want to show the confusion_matrix please pass a value to cm as[show or skip]\n",
    "modeling(model_lg_tuned, name2, cm='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "475f228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       429\n",
      "           1       0.66      0.62      0.64       335\n",
      "           2       0.72      0.69      0.71       317\n",
      "           3       0.97      0.94      0.95       369\n",
      "\n",
      "    accuracy                           0.81      1450\n",
      "   macro avg       0.80      0.79      0.79      1450\n",
      "weighted avg       0.80      0.81      0.80      1450\n",
      "\n",
      "Random Forest after tuning full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       429\n",
      "           1       0.65      0.63      0.64       335\n",
      "           2       0.72      0.70      0.71       317\n",
      "           3       0.97      0.94      0.96       369\n",
      "\n",
      "    accuracy                           0.80      1450\n",
      "   macro avg       0.80      0.79      0.79      1450\n",
      "weighted avg       0.80      0.80      0.80      1450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(random_state = 42)\n",
    "name3 = 'Random Forest'\n",
    "cm = 'skip'\n",
    "modeling(model_rf, name3, cm)\n",
    "model_rf_tuned = RandomForestClassifier(class_weight = {0:0.9,1:1,2:1,3:1},random_state = 42, min_samples_leaf = 2, max_depth = 22, n_estimators = 2000)\n",
    "name4 = 'Random Forest after tuning'\n",
    "cm = 'skip'\n",
    "modeling(model_rf_tuned, name4, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "7894813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       429\n",
      "           1       0.50      0.46      0.48       335\n",
      "           2       0.62      0.57      0.59       317\n",
      "           3       0.97      0.83      0.89       369\n",
      "\n",
      "    accuracy                           0.71      1450\n",
      "   macro avg       0.70      0.69      0.69      1450\n",
      "weighted avg       0.71      0.71      0.70      1450\n",
      "\n",
      "KNN after tuning full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       429\n",
      "           1       0.51      0.49      0.50       335\n",
      "           2       0.61      0.60      0.61       317\n",
      "           3       0.98      0.83      0.90       369\n",
      "\n",
      "    accuracy                           0.72      1450\n",
      "   macro avg       0.71      0.70      0.70      1450\n",
      "weighted avg       0.72      0.72      0.72      1450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn = KNeighborsClassifier()\n",
    "name5 = 'KNN'\n",
    "cm = 'skip'\n",
    "modeling(model_knn, name5, cm)\n",
    "model_knn_tuned = KNeighborsClassifier(n_neighbors = 17,  weights = 'distance')\n",
    "name6 = 'KNN after tuning'\n",
    "cm = 'skip'\n",
    "modeling(model_knn_tuned, name6, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "7e1b604d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:22:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       429\n",
      "           1       0.64      0.67      0.66       335\n",
      "           2       0.74      0.70      0.72       317\n",
      "           3       0.98      0.95      0.96       369\n",
      "\n",
      "    accuracy                           0.81      1450\n",
      "   macro avg       0.80      0.80      0.80      1450\n",
      "weighted avg       0.81      0.81      0.81      1450\n",
      "\n",
      "[22:22:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:22:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost after tuning full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       429\n",
      "           1       0.66      0.67      0.67       335\n",
      "           2       0.74      0.70      0.72       317\n",
      "           3       0.97      0.95      0.96       369\n",
      "\n",
      "    accuracy                           0.82      1450\n",
      "   macro avg       0.81      0.80      0.81      1450\n",
      "weighted avg       0.82      0.82      0.81      1450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model_xgb = XGBClassifier(random_state = 42)\n",
    "name7 = 'XGBoost'\n",
    "cm = 'skip'\n",
    "modeling(model_xgb, name7, cm)\n",
    "model_xgb_tuned = XGBClassifier(class_weight = {0:0.9,1:1,2:1,3:1},max_depth = 5, n_estimators = 200,\n",
    "                                random_state = 42, n_jobs = 10, objective = 'multi:softmax')\n",
    "name8 = 'XGBoost after tuning'\n",
    "cm = 'skip'\n",
    "modeling(model_xgb_tuned, name8, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "492f1f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       429\n",
      "           1       0.56      0.57      0.57       335\n",
      "           2       0.67      0.65      0.66       317\n",
      "           3       0.96      0.91      0.94       369\n",
      "\n",
      "    accuracy                           0.76      1450\n",
      "   macro avg       0.75      0.75      0.75      1450\n",
      "weighted avg       0.76      0.76      0.76      1450\n",
      "\n",
      "SVM after tuning full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       429\n",
      "           1       0.60      0.61      0.61       335\n",
      "           2       0.71      0.67      0.69       317\n",
      "           3       0.97      0.92      0.94       369\n",
      "\n",
      "    accuracy                           0.78      1450\n",
      "   macro avg       0.78      0.77      0.77      1450\n",
      "weighted avg       0.78      0.78      0.78      1450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(random_state = 42)\n",
    "name9 = 'SVM'\n",
    "cm = 'skip'\n",
    "modeling(svm_model, name9, cm)\n",
    "svm_model_tuned = SVC(class_weight = {0:0.9,1:1,2:1,3:1},random_state = 42, gamma = 1, C = 100)\n",
    "name10 = 'SVM after tuning'\n",
    "cm = 'skip'\n",
    "modeling(svm_model_tuned, name10, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "40b35482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       429\n",
      "           1       0.55      0.56      0.55       335\n",
      "           2       0.63      0.62      0.62       317\n",
      "           3       0.91      0.92      0.92       369\n",
      "\n",
      "    accuracy                           0.74      1450\n",
      "   macro avg       0.73      0.73      0.73      1450\n",
      "weighted avg       0.74      0.74      0.74      1450\n",
      "\n",
      "Decision Tree after tuning full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       429\n",
      "           1       0.56      0.66      0.61       335\n",
      "           2       0.72      0.60      0.65       317\n",
      "           3       0.96      0.92      0.94       369\n",
      "\n",
      "    accuracy                           0.76      1450\n",
      "   macro avg       0.76      0.75      0.76      1450\n",
      "weighted avg       0.77      0.76      0.76      1450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_dt = DecisionTreeClassifier(random_state = 42)\n",
    "name11 = 'Decision Tree'\n",
    "modeling(model_dt, name11, cm='skip')\n",
    "model_dt_tuned = DecisionTreeClassifier(class_weight = {0:0.9,1:1,2:1,3:1}, random_state = 42, min_samples_leaf = 2, max_depth = 12)\n",
    "name12 = 'Decision Tree after tuning'\n",
    "modeling(model_dt_tuned, name12, cm='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "2e2c0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       429\n",
      "           1       0.55      0.56      0.55       335\n",
      "           2       0.63      0.62      0.62       317\n",
      "           3       0.91      0.92      0.92       369\n",
      "\n",
      "    accuracy                           0.74      1450\n",
      "   macro avg       0.73      0.73      0.73      1450\n",
      "weighted avg       0.74      0.74      0.74      1450\n",
      "\n",
      "MultinomialNB after tuning full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       429\n",
      "           1       0.56      0.66      0.61       335\n",
      "           2       0.72      0.60      0.65       317\n",
      "           3       0.96      0.92      0.94       369\n",
      "\n",
      "    accuracy                           0.76      1450\n",
      "   macro avg       0.76      0.75      0.76      1450\n",
      "weighted avg       0.77      0.76      0.76      1450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "model_nb = MultinomialNB()\n",
    "name13 = 'MultinomialNB'\n",
    "modeling(model_dt, name13, cm='skip')\n",
    "model_nb_tuned = MultinomialNB(alpha = 0.5)\n",
    "name14 = 'MultinomialNB after tuning'\n",
    "modeling(model_dt_tuned, name14, cm='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d99e5",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "ebdc0916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>MSE Before</th>\n",
       "      <th>After tuning</th>\n",
       "      <th>MSE After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.81103</td>\n",
       "      <td>0.242759</td>\n",
       "      <td>0.81517</td>\n",
       "      <td>0.244828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.80621</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.80483</td>\n",
       "      <td>0.255172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.76207</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>0.265517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.73862</td>\n",
       "      <td>0.386897</td>\n",
       "      <td>0.76345</td>\n",
       "      <td>0.346897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.73862</td>\n",
       "      <td>0.386897</td>\n",
       "      <td>0.76345</td>\n",
       "      <td>0.346897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.72966</td>\n",
       "      <td>0.351034</td>\n",
       "      <td>0.73655</td>\n",
       "      <td>0.321379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.70690</td>\n",
       "      <td>0.424828</td>\n",
       "      <td>0.71586</td>\n",
       "      <td>0.386897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Accuracy score  MSE Before  After tuning  MSE After\n",
       "3              XGBoost         0.81103    0.242759       0.81517   0.244828\n",
       "1        Random Forest         0.80621    0.260000       0.80483   0.255172\n",
       "4                  SVM         0.76207    0.289655       0.78207   0.265517\n",
       "5        Decision Tree         0.73862    0.386897       0.76345   0.346897\n",
       "6        MultinomialNB         0.73862    0.386897       0.76345   0.346897\n",
       "0  Logistic Regression         0.72966    0.351034       0.73655   0.321379\n",
       "2                  KNN         0.70690    0.424828       0.71586   0.386897"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame(score_values)\n",
    "comparison.sort_values('After tuning', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8860a1d0",
   "metadata": {},
   "source": [
    "## Baseline model (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "8f590fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     feature  importance\n",
      "8   sit and bend forward_cm      1691.0\n",
      "4                body fat_%      1588.0\n",
      "11                      BMI      1490.0\n",
      "9            sit-ups counts      1336.0\n",
      "0                       age      1290.0\n",
      "7                 gripForce      1276.0\n",
      "10            broad jump_cm      1138.0\n",
      "2                 height_cm      1038.0\n",
      "3                 weight_kg       943.0\n",
      "6                  systolic       896.0\n",
      "5                 diastolic       697.0\n",
      "1                    gender       112.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's take a closer look at the feature importance with the xgb_model:\n",
    "xgb_fea_imp=pd.DataFrame(list(model_xgb_tuned.get_booster().get_fscore().items()),\n",
    "columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "print('',xgb_fea_imp)\n",
    "xgb_fea_imp.to_csv('xgb_fea_imp.csv')\n",
    "\n",
    "from xgboost import plot_importance\n",
    "plot_importance(model_xgb, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "9e8a2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = plot_importance(model_xgb, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "ee9e6fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = {'Feature':['sit and bend forward_cm', 'body fat_%', 'BMI', 'sit-ups counts', 'age', 'gripForce', 'broad jump_cm', 'height_cm', 'weight_kg', 'systolic', 'diastolic', 'gender',],\n",
    "     'importance': [1691.0, 1588.0, 1490.0, 1336.0, 1290.0, 1276.0, 1138.0, 1038.0, 943.0, 896.0, 697.0, 112.0]}\n",
    "\n",
    "df_fi = pd.DataFrame(fi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "24862968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4MAAAHiCAYAAABSoBksAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3N0lEQVR4nO3deZxcZZ3v8U9ngQRIQEKAIAI6mJ9sAiog4pK5gooiyAiiAoojKKOoc90GL8gwOl5H54qKDogiwogz4qAoAnEBRRYFBWUR5He5DkSRqBFkiRKydO4fz2kpuqu7q5NUV6efz/v1yitdp07V+dVTZ/ue85xTfatXr0aSJEmSVJcpvS5AkiRJkjT+DIOSJEmSVCHDoCRJkiRVyDAoSZIkSRWa1usCumhDYC9gMbCqx7VIkiRJ0nibCswDfgI8OvjJyRwG9wKu7nURkiRJktRjzwOuGTxwMofBxQB//OOf6O/35zMkSZIk1WXKlD6e8ISNoclGg03mMLgKoL9/tWFQkiRJUs3aXjbnDWQkSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqtC0XhfQK5tvOoOpG0zvdRlds2r5Cu5/cFmvy5AkSZI0QVUbBqduMJ0lZ57f6zK6Zu7fHQUYBiVJkiS1ZzdRSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmq0LRuvnlEzAZ+CByUmXdHxL7Ax4FZwC3A6zNzeUTsAZwNzAauAo7PzJURsR1wPrAlkMCRmbm0mzVLkiRJUg26dmYwIvYBrgHmN49nA18D3pSZuzSjvbH5/3zghMycD/QBxzXDzwDOyMynATcA7+9WvZIkSZJUk252Ez0OeCtwb/P4AOBHmXlL8/htwEURsT0wMzOva4afCxweEdOB5wMXtg7vYr2SJEmSVI2udRPNzGMBImJg0I7A0oj4MvA04FrgXcCewOKWly4GtgW2AB7KzJWDho/JnDmbrEn5k8LcubN6XYIkSZKkCaqr1wy2mdaLgWcDvwI+D5wIfBdY3TJeH9BPOWu5etB79I91ovfdt5T+/sFvU0dQWrLk4V6XIEmSJKlHpkzpG/Hk2HjeTfS3wHWZeVdmrgK+AuwN3APMaxlva0rX0t8Dm0bE1Gb4PB7rcipJkiRJWgvjeWbwO8A/RcSTMvPXwEHAjZm5KCKWRcR+mXktcDSwMDNXRMTVwBHAfwCvAxaOY71V2nzTDZi6wYa9LqNrVi1/lPsfXN7rMiRJkqSeG7cwmJm/jog3A9+MiBnATcC7m6ePBD7X3HH0p8DpzfC3AOdFxMmUrqWvGa96azV1gw351emH9bqMrtnu7RcChkFJkiSp62EwM3do+ftS4NI249xM6TI6ePgiYEEXy5MkSZKkKo3nNYOSJEmSpAnCMChJkiRJFTIMSpIkSVKFDIOSJEmSVCHDoCRJkiRVyDAoSZIkSRUyDEqSJElShQyDkiRJklQhw6AkSZIkVcgwKEmSJEkVMgxKkiRJUoUMg5IkSZJUIcOgJEmSJFXIMChJkiRJFTIMSpIkSVKFDIOSJEmSVCHDoCRJkiRVyDAoSZIkSRUyDEqSJElShQyDkiRJklQhw6AkSZIkVWharwuQ1gebbboB0zfYsNdldM2K5Y/ywIPLe12GJEmSxpFhUOrA9A025Nuff2mvy+iaF7/xMsAwKEmSVBO7iUqSJElShQyDkiRJklQhw6AkSZIkVcgwKEmSJEkVMgxKkiRJUoUMg5IkSZJUIcOgJEmSJFXIMChJkiRJFTIMSpIkSVKFDIOSJEmSVCHDoCRJkiRVyDAoSZIkSRUyDEqSJElShQyDkiRJklQhw6AkSZIkVcgwKEmSJEkVMgxKkiRJUoWmdfPNI2I28EPgoMy8u2X4CcBhmbmgebwHcDYwG7gKOD4zV0bEdsD5wJZAAkdm5tJu1ixJkiRJNejamcGI2Ae4Bpg/aPjOwImDRj8fOCEz5wN9wHHN8DOAMzLzacANwPu7Va8kSZIk1aSb3USPA94K3DswICI2BM4CTmkZtj0wMzOvawadCxweEdOB5wMXtg7vYr2SJEmSVI2udRPNzGMBIqJ18IeBc4C7WoZtAyxuebwY2BbYAngoM1cOGj4mc+ZsMtaXTBpz587qdQkTku3Snu0iSZJUl65eM9gqIg4AtsvMd0bEgpanpgCrWx73Af1thtMMH5P77ltKf//gt6ljx3fJkofH/BrbpT3bRZIkSeubKVP6Rjw5Np53E30NsEtE3ES5WcyzIuIC4B5gXst4W1O6lv4e2DQipjbD59HS5VSSJEmStObGLQxm5t9m5k6ZuQdwLHBDZh6RmYuAZRGxXzPq0cDCzFwBXA0c0Qx/HbBwvOqVJEmSpMlsovzO4JHAxyPiDmAT4PRm+FuAN0XE7cDzgJN7VJ8kSZIkTSpdv2YwM3doM+xKYEHL45uBvduMt6h1PEmSJEnSujFRzgxKkiRJksaRYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqNK3XBUhaP2262XQ2mD6j12V0zfIVy3jwgRW9LkOSJKlrDIOS1sgG02dw1hdf3OsyuubNR38bMAxKkqTJy26ikiRJklQhw6AkSZIkVcgwKEmSJEkVMgxKkiRJUoUMg5IkSZJUIcOgJEmSJFXIMChJkiRJFTIMSpIkSVKFDIOSJEmSVKFpvS5AkiaT2ZttwIbTN+x1GV3z6IpHeeiB5b0uQ5IkrQOGQUlahzacviFvuOglvS6ja75w6LcAw6AkSZOB3UQlSZIkqUKGQUmSJEmqkN1EJUldN2uzGcyYPr3XZXTNshUrePiBZb0uQ5KkMTEMSpK6bsb06bzson/tdRldc+mh7+FhDIOSpPWL3UQlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqULTuvnmETEb+CFwUGbeHRFvAt4OrAZuAN6cmcsjYg/gbGA2cBVwfGaujIjtgPOBLYEEjszMpd2sWZIkSZJq0LUzgxGxD3ANML95PB94D/Ac4OnNtN/ajH4+cEJmzgf6gOOa4WcAZ2Tm0yjh8f3dqleSJEmSatLNbqLHUcLevc3jR4G3ZOZDmbkauBXYLiK2B2Zm5nXNeOcCh0fEdOD5wIWtw7tYryRJkiRVo2vdRDPzWICIGHi8CFjUDJsLnAAcA2wDLG556WJgW2AL4KHMXDlo+JjMmbPJGtU/GcydO6vXJUxItkt7tstQtkl7tkt7toskaX3T1WsG24mIJwILgc9n5pURsR/lGsIBfUA/5azl6kEv7x/r9O67byn9/YPfpo6N9pIlD4/5NbZLe7bLULZJe7ZLe7aLJEnjb8qUvhFPjo3r3UQj4mmUG8qcl5kfbAbfA8xrGW1rStfS3wObRsTUZvg8HutyKkmSJElaC+MWBiNiFvAd4OTM/NjA8Kb76LLmDCHA0cDCzFwBXA0c0Qx/HeWMoiRJkiRpLY1nN9Fjga2Ad0XEu5phF2fmKcCRwOean6L4KXB68/xbgPMi4mTgV8BrxrFeSZIkSZq0uh4GM3OH5s+PN//ajXMzsHeb4YuABd2qTZIkSZJqNa7XDEqSJEmSJgbDoCRJkiRVyDAoSZIkSRUyDEqSJElShQyDkiRJklQhw6AkSZIkVcgwKEmSJEkVMgxKkiRJUoUMg5IkSZJUIcOgJEmSJFVoWq8LkCSpVrM2m8GM6dN7XUbXLFuxgocfWNbrMiRJwzAMSpLUIzOmT+egC7/U6zK65pLDjuRhDIOSNFHZTVSSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpApN63UBkiRJA2ZtNpMZ0yfv7smyFSt5+IFHel2GJAGGQUmSNIHMmD6NV1x4Ra/L6JqvH/ZCHu51EZLUsJuoJEmSJFXIMChJkiRJFTIMSpIkSVKFDIOSJEmSVKGu3kAmImYDPwQOysy7I2J/4DRgJnBBZp7cjLcHcDYwG7gKOD4zV0bEdsD5wJZAAkdm5tJu1ixJkiRJNejamcGI2Ae4BpjfPJ4JnAMcAuwE7BURBzajnw+ckJnzgT7guGb4GcAZmfk04Abg/d2qV5IkSZJq0s1uoscBbwXubR7vDdyZmXdl5kpKADw8IrYHZmbmdc145zbDpwPPBy5sHd7FeiVJkiSpGl3rJpqZxwJExMCgbYDFLaMsBrYdYfgWwENNcGwdPiZz5mwy1pdMGnPnzup1CROS7dKe7TKUbdKe7dKe7dKe7TKUbSJpougoDEbEFOBdwK7ACc2/j2bmqjFMawqwuuVxH9A/huE0w8fkvvuW0t8/+G3qWBEvWTL2n7W1XdqzXYayTdqzXdqzXdqzXYayTSRp3ZkypW/Ek2OddhP9V2A3SlfPPuAlwMfHWMs9wLyWx1tTupAON/z3wKYRMbUZPo/HupxKkiRJktZCp2HwhcAxwLLMfAh4EXDAGKd1PRARsWMT8F4LLMzMRcCyiNivGe/oZvgK4GrgiGb464CFY5ymJEmSJKmNTsPgisz8SxfNzHwUWDnC+ENk5jJKoPwqcDtwB4/dHOZI4OMRcQewCXB6M/wtwJsi4nbgecDJY5mmJEmSJKm9Tm8g8/OIeCswNcodYd4J3NTJCzNzh5a/rwB2bzPOzZQuqIOHLwIWdFijJEmSJKlDnZ4ZfAfwDGArym8Hbgz8fZdqkiRJkiR1WUdhsLlO8EOZuRXwFOBjmXlfVyuTJEmSJHVNR2EwIt4GfL15uAXw1Yh4Y7eKkiRJkiR1V6fdRN8MPBcgM+8C9qR0HZUkSZIkrYc6DYNTm66iAGTmgwz9QXhJkiRJ0nqi07uJ3hER/wJ8lhIC3wDc2bWqJEmSJEld1emZweOB+cDPgBuav/+uW0VJkiRJkrqrozODmfk74G+6XIskSZIkaZx0FAabH5o/Edgc6BsYnpkHd6kuSZIkNWZvthEbTp/a6zK65tEVq3jogT/3ugypOp1eM3ge8GPgB3jjGEmSpHG14fSpvP2iX/e6jK45/dAn9boEqUqdhsGNM/PtXa1EkiRJkjRuOr2BzJ0RMa+rlUiSJEmSxk2nZwanALdFxI3AIwMDvWZQkiRJktZPnYbBi5p/kiRJkqRJoNOfljiv9XFE9AE7dqUiSZIkSVLXdfrTEm8G/hXYuGXwEmDrbhQlSZIkSequTm8gcyJwAHApsCdwCnYblSRJkqT1Vqdh8P7MvB64CdgqMz8EvKBrVUmSJEmSuqrTMLgiIp4A3Ans3Qyb2p2SJEmSJEnd1undRD8LXAK8HLgpIg4F7uhaVZIkSZKkruo0DH4BuCAz/xQR+wLPAn7cvbIkSZKkkW222cZMn95pR7f1z4oV/TzwwJ96XYYmsU7D4I2Z+QyAzPwN8JuI+Dmwa9cqkyRJkkYwffoUFl7wh16X0TUHHrFFr0vQJDdiGIyIK4C9gI0i4qGWp6YCP+lmYZIkSZKk7hntzOChwObAOcAbWoavBBZ3qyhJkiRJUneNGAYz8yHgoYhYnZmLxqkmSZIkSVKXdXrF7aYRsXFXK5EkSZIkjZtObyDzZ2BRRNwCLB0YmJkHd6UqSZIkSVJXdRoGP9/VKiRJkiRJ46qjbqKZeR5wZfNwOnBtM0ySJEmStB7qKAxGxIuBG4BXAAcDP4mIQ7pYlyRJkiSpizrtJvpB4AWZeTtAROwCnA98o1uFSZIkSZK6p9O7iW4wEAQBMvM2yg/PS5IkSZLWQ52GwUci4lkDD5q//9ydkiRJkiRJ3dZpN9H3ApdExJ3N4wAO705JkiRJkqRu6ygMZubVEbEzsA+le+iPMvO+rlYmSZIkSeqajsJgREwFXg28GFgFbAGc272yJEmSJEnd1Ok1g6cDr6LcPfQy4I0R8c9dq0qSJEmS1FWdXjP4ImDnzFwBEBHnAzcDJ3erMEmSJElS93R6ZnAJjw+O/cAD67waSZIkSdK46PTM4E3A1RFxLrASOAL4Q0S8EyAzT+tKdZIkSZKkrug0DM4EbgWe2Ty+u/l/N2D1WCcaEUcB72seLszMd0fE/sBpzbQuyMyTm3H3AM4GZgNXAcdn5sqxTlOSJEmS9JhOf1riDetqghGxEeWGNPMpXU2vjYiXA/8GvAD4NXBpRByYmQuB84FjM/O6iPg8cBxw5rqqR5IkSZJq1OlPSywATgQ2bx2emXuvwTSnUq5V3Bj4EzAdeAi4MzPvaqZ3PnB4RNwOzMzM65rXngv8E4ZBSZIkSVornXYTPZtyNu+XazvBzHw4It4P3AH8GfgBsA2wuGW0xcC2Iwzv2Jw5m6xVveuzuXNn9bqECcl2ac92Gco2ac92ac92ac92Gco2ac92ac92UTd1GgZ/l5mnr4sJRsTTgb8FtgcepHQDnc/jrz3so9yxdMowwzt2331L6e8felljDQvWkiUPj/k1tkt7tstQtkl7tkt7tkt7tstQtkl7tkt7tos0silT+kY8OdZpGPxmRLwF+DawYmBgZv5qDWp6MXBFZv4eoLlD6buBVS3jbA3cC9wDzGszXJIkSZK0Fjr9ncE5wKcpPzFxW/Pv52s4zZuB/SNi44joA14OXA9EROwYEVOB11LuMroIWBYR+zWvPRpYuIbTlSRJkiQ1Oj0z+HJgXmb+bm0nmJnfiYg9gRspZxl/DJwKfBf4KjADuAy4sHnJkcDnImI28FPKtYuSJEmSpLXQaRj8PbBkXU00Mz8CfGTQ4CuA3duMezOwJnctlSRJkiQNo9MweCtwTUR8E3h0YGBmntaVqiRJkiRJXdVpGNyI8lMQT+1iLZIkSZKkcTJiGIyIr2Tmq4BntXl66O81SJIkSZLWC6OdGRy4ru+EbhciSZIkSRo/I4bBzLyx+f8H41OOJEmSJGk8dPo7g5IkSZKkScQwKEmSJEkVMgxKkiRJUoUMg5IkSZJUIcOgJEmSJFXIMChJkiRJFTIMSpIkSVKFDIOSJEmSVCHDoCRJkiRVyDAoSZIkSRUyDEqSJElShQyDkiRJklQhw6AkSZIkVcgwKEmSJEkVMgxKkiRJUoWm9boASZIkSevO5ptuzNQNJu85n1XL+7n/wT/1uoxJwTAoSZIkTSJTN5jC3Z/4ba/L6Jod/n7rXpcwaUzeQwaSJEmSpGEZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqULTejHRiHg58I/AxsB3MvMdEbE/cBowE7ggM09uxt0DOBuYDVwFHJ+ZK3tRtyRJkiRNFuN+ZjAingJ8BngF8HTgGRFxIHAOcAiwE7BXMwzgfOCEzJwP9AHHjXfNkiRJkjTZ9KKb6KGUM3/3ZOYK4Ajgz8CdmXlXc9bvfODwiNgemJmZ1zWvPRc4vAc1S5IkSdKk0otuojsCyyPiYmA74BLgNmBxyziLgW2BbYYZ3rE5czZZq2LXZ3Pnzup1CROS7dKe7TKUbdKe7dKe7dKe7TKUbdKe7dKe7dKe7bJu9CIMTgOeDywAlgIXA48Aq1vG6QP6KWcu2w3v2H33LaW/f/WQ4TXMQEuWPDzm19gu7dkuQ9km7dku7dku7dkuQ9km7dku7dku7dkuGjBlSt+IJ8d6EQZ/C1yemUsAIuIiStfPVS3jbA3cC9wDzGszXJIkSZK0FnpxzeAlwIsjYrOImAocCFwIRETs2Ax7LbAwMxcByyJiv+a1RwMLe1CzJEmSJE0q4x4GM/N64KPANcDtwCLgTOAY4KvNsDsoARHgSODjEXEHsAlw+jiXLEmSJEmTTk9+ZzAzz6H8lESrK4Dd24x7M7D3eNQlSZIkSbXoRTdRSZIkSVKPGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkio0rZcTj4j/A2yRmcdExP7AacBM4ILMPLkZZw/gbGA2cBVwfGau7FHJkiRJkjQp9OzMYES8EHh98/dM4BzgEGAnYK+IOLAZ9XzghMycD/QBx/WgXEmSJEmaVHoSBiNic+BDwP9uBu0N3JmZdzVn/c4HDo+I7YGZmXldM965wOHjXa8kSZIkTTa96iZ6FnAS8KTm8TbA4pbnFwPbjjC8Y3PmbLLmVa7n5s6d1esSJiTbpT3bZSjbpD3bpT3bpT3bZSjbpD3bpT3bpT3bZd0Y9zAYEccCv87MKyLimGbwFGB1y2h9QP8Iwzt2331L6e9fPWR4DTPQkiUPj/k1tkt7tstQtkl7tkt7tkt7tstQtkl7tkt7tkt7tosGTJnSN+LJsV6cGTwCmBcRNwGbA5sA2wOrWsbZGrgXuAeY12a4JEmSJGktjPs1g5l5QGbumpl7AKcAFwMHAhERO0bEVOC1wMLMXAQsi4j9mpcfDSwc75olSZIkabKZEL8zmJnLgGOArwK3A3cAFzZPHwl8PCLuoJxFPL0XNUqSJEnSZNLT3xnMzHMpdwglM68Adm8zzs2Uu41KkiRJktaRCXFmUJIkSZI0vgyDkiRJklQhw6AkSZIkVcgwKEmSJEkVMgxKkiRJUoUMg5IkSZJUIcOgJEmSJFXIMChJkiRJFTIMSpIkSVKFDIOSJEmSVCHDoCRJkiRVyDAoSZIkSRUyDEqSJElShQyDkiRJklQhw6AkSZIkVcgwKEmSJEkVMgxKkiRJUoUMg5IkSZJUIcOgJEmSJFXIMChJkiRJFTIMSpIkSVKFDIOSJEmSVCHDoCRJkiRVyDAoSZIkSRUyDEqSJElShQyDkiRJklQhw6AkSZIkVcgwKEmSJEkVMgxKkiRJUoUMg5IkSZJUIcOgJEmSJFXIMChJkiRJFTIMSpIkSVKFDIOSJEmSVCHDoCRJkiRVyDAoSZIkSRUyDEqSJElShQyDkiRJklQhw6AkSZIkVcgwKEmSJEkVmtaLiUbEPwKvah5empnvjYj9gdOAmcAFmXlyM+4ewNnAbOAq4PjMXDn+VUuSJEnS5DHuZwab0PciYE9gD+CZEfEa4BzgEGAnYK+IOLB5yfnACZk5H+gDjhvvmiVJkiRpsulFN9HFwLsyc3lmrgB+AcwH7szMu5qzfucDh0fE9sDMzLyuee25wOE9qFmSJEmSJpVx7yaambcN/B0RT6V0F/0UJSQOWAxsC2wzzPCOzZmzyRrXur6bO3dWr0uYkGyX9myXoWyT9myX9myX9myXoWyT9myX9myX9myXdaMn1wwCRMQuwKXAe4CVlLODA/qAfsqZy9VthnfsvvuW0t+/esjwGmagJUseHvNrbJf2bJehbJP2bJf2bJf2bJehbJP2bJf2bJf2bBcNmDKlb8STYz25m2hE7AdcAZyYmecB9wDzWkbZGrh3hOGSJEmSpLXQixvIPAn4OvDazPxyM/j68lTsGBFTgdcCCzNzEbCsCY8ARwMLx7tmSZIkSZpsetFN9N3ADOC0iBgY9hngGOCrzXOXARc2zx0JfC4iZgM/BU4fz2IlSZIkaTLqxQ1k3gG8Y5ind28z/s3A3l0tSpIkSZIq05NrBiVJkiRJvWUYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmq0LReFyBJkiRJ3bT5pjOZusHkjT6rlq/k/gcfGfPrJm+LSJIkSRIwdYNp/O6TP+p1GV2z1Tv2XaPX2U1UkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKGQYlSZIkqUKGQUmSJEmqkGFQkiRJkipkGJQkSZKkChkGJUmSJKlChkFJkiRJqpBhUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSaqQYVCSJEmSKmQYlCRJkqQKTet1AZ2IiNcCJwPTgU9k5r/1uCRJkiRJWq9N+DODEfFE4EPAc4E9gDdFxM49LUqSJEmS1nPrw5nB/YHvZeb9ABFxIXAY8IFRXjcVYMqUvmFHmDJr43VU4sQ00mcfydRZc9dxJRPLmrbLjE22XMeVTCxr0i6bbLxVFyqZONZ0Xpmzke3SzpYbzV7HlUwsa94ubosG23KjGV2oZOJY03ll842mruNKJpY1bZeZG034cxtrZU3bZdps55chr5m1YRcqmTjatUnLsLYzRN/q1au7WNLai4j3ARtn5snN42OBvTPzTaO89LnA1d2uT5IkSZImuOcB1wweuD6cGZwCtCbWPqC/g9f9hPKhFwOrulCXJEmSJE1kU4F5lGw0xPoQBu+hhLoBWwP3dvC6R2mTfiVJkiSpIr8c7on1IQxeDpwaEXOBPwGvBEbrIipJkiRJGsGEv+I2M38DnAR8H7gJ+I/M/HFPi5IkSZKk9dyEv4GMJEmSJGndm/BnBiVJkiRJ655hUJIkSZIqZBiUJEmSpAoZBiVJkiSpQoZBSZIkSarQhAuDEXFZRGwTEU+OiM934f2PiYhz2wy/OyJ26ML0royIBW2GnxMR/x0Rr1nX0xyLwfVFxIKIuHIt3m9Mr++kHSLiCxGx/Sjvc1hE/DIirouILZph20XEeR0XP06aNloaETdFxM0R8YuIeEfz3JUR8WBEbDjoNTcNtOtw8/B46/ay2iudzG8aPxFxcER8YJRxzo2IXzXLycC/D41XjW3qWav16BimM9z27LKI2Kbb0x8va7BduWmU54drt00j4qIxF7ieaNbXl40yzqkRcWqb4aOu5yNih4i4e+2qnLg63Be5splfnxURZ49XbetCsx79X6PNIyO8/vsdjHN3M5+Mul6frMZr+zAWE+5H5zPzpVAaC/ir3lbTVccAMzJzea8L6bFjGL0d/hr4p1He5yRgX+D1wGuB04F/BD64DmrshhsycwFARMwCbo+I7zbPPQS8CPhm83wA2wAPjH+Zw5vEy2on85vGSWZeDFzcwainZOa5XS5nvTCwbNYqM/dYw5c+AdhzHZYyoWTmvcCazhvbM7nW82ui421DZt4AHNvdcrri3rVYfyzodMQxrNc1DnoWBiNiW+BLwMZAP/D2zLyuOaq0gLIz/5SI+LfMfGvL66YBZwK7AlsBtwCvaf6+CPg5ZWX+O+DwzLw/Io4GTqbsZC8Clg5T1qkRsTuwDHhzZt4SEVsBZwFPaup8X2Ze3hw5eyLwVMpK8uzM/FBzRuds4FnA3cAWbT77xUAf8OOIeBHwMuBdwGrgRuCEzFwaEUuAG4B5wIbA32TmLyLiP4AHM/PvImLf5rMdMkK7fAv4A/AIcNBo9QFbRMS3ms93PXAHcBwws6njd8BmwOXATs14ALMo89QDEbEj8D1gh8zsbwLDP2TmgSO0wzuAFwKbA/cCRwBvoAShyyLieZl5X5t6AZZT5qVZwMMRsQewNDP/3zDjTyQzgVXAg83jrwKH0YRBSjtcCOw8/qWt+bLavPZUgMw8tXk88JoFlHlxS8r8/U3KMvDEdtMa9J77Ax+j9GxYRAn/S4FPUOaf1cAXM/MjzXx3akvwPhe4svk3ZH0BvImW+Q14H3BAU8vXM3NcQ+II67vjgLdRDhDcAfwyM0+NiJcAHwCmA3cBx42wzEwIEfFhyvz+B2AxZQfhRB5bZ30JWJCZxzTzz1co3wnA32bmz0Z5/zcw+vp1L+CfgUOBlcBZmfnJZj12JjAH+DPwttGm12LwevStmflom+m+BziKsg74DvDezFzVnNl83PowM3/XyfZs0HK2IDOPaYZfCZzajHYSZb35ZEqbLwVeQVknv7SZ1u+BrwHPAR4GjszMu4f7wM169yxgI+B+4Ehgx06mNXJTAjC3OWPxV0BSltcjgL+nrAtupLTxsohYnZl9EbEp8O9NDf8NbEv5jgF2bNpjO+CKzDyOsi7bJiIuysxDGUZEvJbyHawGfkJZHk9q3ms+MBcY+P72AW4GXp2Z6+yHnSPiVuBVI+wTXA28CpgKfBv4B8q+ypWZuUPLev0JwK3ACzJz2+bt946IH1Lm3S806+9h1/PD1PdK4BRgf8p+w3DTGjdttmXfoMx/+zXPH0P5vs4EPkvZn1lG2Q95JY/fNjwV+CQwg7KuenPr/kbrtqfdcpGZ93T5444qIvoo29KDKOuYqcCVEXF3M4/sCnwK2ISyrf5wZn4mIl4IfJQy//+Rsk06pXnP6zNzn4g4iLJOnUJZ9t7cupw3bT2wXh+yTc/Mh7rfAp0ZZhvVT/t1z2LK/tpzKduSV2XmXc0+7scp89MdLe/ddhvT7KvMoay73puZA/uDXdHLbqJvBC7JzGdRZqLnDnr+7ZSzJ4NXOs8BlmfmvpRG2ozHjnTtDpyWmbtSdpKObLrKfBR4PuXM0awRarozM/eknE0a6F74SeCczHwmcDBwVnMmB+DplDM4+wAnRsRmlB00MnOn5jMMOZKWmQc3/+9B2cE7ibJy3A34E+WMFpSg9pFmvG9QNiwAu/FYe70EuGSUdgngqMw8oJP6KBvstzWfb3vKRuSllBXFnZQV4++AF1N2NmY30wvKjsM8YAllZ3RB856vA84doR1mA08DnpOZ84FfNTX/C2Ul9dJRdmpPAr5O2bE/H3g/ZWM8UT2r6cp2CyWUX0n5nAALgQURMb15fBDlO+6VNV1WR/Ncyg7dLsCzKTtpI06rOdjyJeD1zfJyK+Vs8PGUAzZPB/YGXhkRLxtl+kPWF63zG2UDeGBm7g7sB+wcETPG+BnXVrvl+r3AW4FnAgM7JUTEXOBfgBc367FvAx8Z53rHJCJeTvmOd6G0+cBZmdZ11mB/aj7fKTy2ngb4QDy+m+isiNiNztavr6B8x7tR5p83RMTWzfu/NzOfQTlQ8OUxfLzW9egsyjw6eLr7U7Yrz2o++47A8c0OwpD14Ri3Z6PZp6npWcAJwJJmubsFeHUzzlzgR5n5dMpnP32U9/wS8MGmrb9MOcDX6bRGsx1lvt8J2Jpy1uU4ShvtAfweePeg15wCZGbuQjmjs9ug9/ub5v0OjIhdKOuye0cJgk+k7NS9qHnfqZQDujTvv4Ayr3yBsvztCjyDMh+sS5cy8j7BMykHG/akhLojB73+k8AFzXd7IY8d1IWyX/LXzXu8p9nn6Xg93+z4nkJpoyWjTGs8Dd6+LAfmRcTAftDAfsr/BD7WjPc54NmDtg0PU+bvE5rtw2eA/xxhusMtF732Ssr8sQtlW7zjoOePBf45M/eizA//2gw/GTi+aZ/vAs/IzLcDNEFwS0r4fUXznV8LfLpdASNs0yeEYbZRGzP8umdrysGlPYGrgBOaz3gecFiTJR5pmcRI25j7MnOnbgdB6G0YvBx4d3NEaw7DzCiDZeZVwBkR8VbKCuaplJ02gN+3HLX9OeWI6nOAH2bm7zJzJSUoDOfsZhqXAds34W5/mp0Myk76dB4LUN/PzOWZ+XvK0Z5NKRuCrzTvcyfww1E+0guAb7YEnc/y2AoeyhFlgMuAF0bEzsBtwKpmgTsQuLSDdrm7+buT+q7KzDubo5i/puwo7wT8ODOfm5k3Av+XsmO6GyUY3tK0w9mUoyFPAM4Bjo6IjZrP9I3hGqE5ovYu4NiI+BhlR2eT4cZv8/rLM3P3zHw55Tu/CZgTEd+MiAubM7wTyQ2ZuUezotyacjT5xOa5RylHdfdvjsz9N+WIUa+s0bLagW80y+Vyygrwf3Qwrd2A32TmTQCZ+b7M/FTz2nMzc1Vm/pmycXkhI2u3vmj1G+CRiLiWsvH+h8xctiYfdE0Ns1xD2aF5qKlnYCdkH8oO7veb9dUJLeNPVAcAX2nWo3+kHNCBx6+zBvssQLOB3Daaa4Qp3UT3aPn3MJ2vX1/Q1PFoZi5tNvBLKTvTX2ja8z+ATSJiToefrXU9+iUe34VqYLovBP4zM//cbJ/OAV44wvpwLNuz0fw8M3/dLC9/AK5ohi+irL+hHMX+9+bv8yjLWVvN9zAvMy8ByMwzM/M9Y5jWaG7OzLsysx/4BSVUPxW4rvl+DqEE6FYHAF9s6rmBsqM54KrMvD8zHwV+SfteMu3sC1ybzZmdzDw6M7/ePPfd5ntZBCzOzNubx78Zw+fs1Ej7BHtR1gc3Aj+lhPBdBr2+tW0u4vGXISxsloU/UL6vwevGkWxBOSj87/nYmaCRpjWeBm9fPkWZr4+KiO2ArTLzekrQ/nSUayQfpCz7reYDf8zMnwBk5n9RzjRvOniCoywXvbYA+FpmrmhC++BrBd8FzIiI91HO8g3sk10MXBQRnwZ+lpnfGfS6vSn7i3c3jwevd1sNt02fKNpto/oYed3zreb/gf2K3SgHmX7RDD8PICI2YeRtzPWMk56Fwcy8ltLt7duUrh4dJd+IOJiyYf0z5cjbVZQvBsqGa8DqZvjqluehBJXhtD7XB6ygHPX7HwM7GJQV7MAGZW2nB0O/gz5auu9m5sARhB9SzmTsTzmL9APKaevpmfmrUdql9ShEJ/W1Dutv/k2Bv1yAvlnzHlNa3m9lm9f+F2VBOgy4bKQd6Yh4JqWL1BTKkcOLBtXZkYiYQjmqdxrlDMCHKd0uJ8qRuCGydIe4gHJmYsB/UdrtVc1zPTOWZTUiWs/OHMzQ+W16y9+t88oUYGUH01rRvOfA9DZtuv4MtxyNNP12y+9fNDtx+1DOMs8BfhQR84d86C4aZrl+gPbr7qnANS3rqr0oR34nslW0/yyPtBk2YPB8s2qEcTtdvw6er3agtOey1oBJmR/uH2F6I9W5os1029Y3wvpwrNuXkeb/wddpt3uv/nysa+OUUaY3uA1nRMRTxjCt0bS+ZjVlOfhKy3ezN+UASKvh5q9279fp9mbw55zbnJWHx3/ONfmMYzHsPgElwHxi0Hw7uKdMN9oGyv7CwZQzigM3MRppWuNmmO3LuZSz06+hOfCRmRdSzub+mLI/8ZlBb9Xus/RR1hmDjbRc9Npo65OvUHrs3E7pYQFAZn6cEiT/H/DRiDhp0OtGXO8OMtw2faJoN+9OZYR1T8u+7mi5YLRtzEjbwXWqZwtnRHyU0g3oPEojPmPQKCtpP/PsT/kSvkDZGPw17RfAAdcA+0bEE5ugcMQI4x7Z1HYo8IvM/BPlure3NMN3piT9jUZ4j8sp3VOnRLnr1HNGGBfKSvzgiBg48nYcMOSOTM2O6Y8pXTWubOo6iceO5HTaLp3U99wod+KcAjyF0oXzVkpXvq9RjjLOpxydvYVyxHPj5rV/uStocxR4IfC/GdRFtI0XUK5l+AzlrONBLfUPNy+0czTl2q4/ARs0r+2n9OufkCJiKmXF+tOWwd+ifIcHUtqwZ8ayrGZm69mZiylHlXdp3mdvShfiAS9pVvwzKPPNwg6mlcCWzbIIpcvk8ZTl4fURMbU5E30kZTn6A+U6lxnNMva8Dj7ySsoO+Z6UHayrMvPdlA1idPD6dandcg3w0oiYHREbUALfaspRxH1bAuv7gf8zzvWO1eWULr0bRMRsynI/2p1cXw2PW0//cYRxr6SD9SslZL8yIqY388+3KF3l7oyIo5rpHdCM16nW9ejrKJ91sO8Br4mImVGuD31DU99w68OxbM+gzP87RURfRDyZsXdV3KjpJkVT27Drosx8ELin6SIIZV3c7bsFHhoRW0a59ulMyjU8rS6nXFNM02V4V1p2PNvoZFvzE+DZTTdiKF1GDxlj3WttlH2C71F65WzSzFdfpwTFVq1tcyClp89IOt0O35+Z3wPOoJx5W5NpdUW77UtmLgLuAf6O5uxlRFwA7JWZZ1HWowPboYE2SErPo72a8V8FLMrMIQeKerRcdOpy4FURsWFEPIHSxbjVAZQeF9+g7IvQbGOvB2Zl5ico8/9A+6xq5rfrKcvIDs3wN9F+vQvDb9MninbbqM0Yfd3T6hZgqyj3JIFmP7mZN9ZmG7PO9PJIzaeAw5pToxdRNpatfgFsFhFfHDT8c5SN562UsyfXUq7NaKvppvA2yhf6Y8pF98OZ39TzTh7rs/w2ykx9C+UMzVFN96PhnNFM4xdNrT8fYVwy8xbK2asfRMQdlJns5GFGvxTYODPvoOykbsVj15J12i6d1HcbpbvSrc3fH6J0C1gO7EDprrY1cF5mrqBcY7lTRPyUoUH5y8BDTdeLkVwA7N7UfyXlBgsD9V9CuWh72O8ZyhE3yo0YBm5//UlKN6r/RVlYJ5KBawZ/Rrm5wJ9pub6r6bp0LXDHSGdUx8maLqtQvv/NI+J2yrLUevONgW4pN1O6PX57tGk1bXEU8O/NMrkz5Tq5sygb9JubaXwzMy/KzNsoy81tlOXi6g4+7yVNXQ8APwJ+3szbtzP+wbzdcj2Xcu3Wjyif52Hgkcz8LfC3wFea8Z9B6eYzYWXmpZSN388o39O9jH40dL9m/ng3o1xb0un6tem6di3lgMxPgE9m5v+lHFQ4tpnXPky5iUunNwFpXY/+hsfWS63TvYQyv93QjP8ryjLQdn04xu0ZzXi/puxwfZISJsfq8Obzv5iRd3igLJunNN/PEZSb43TLg5TrAL9HabuplHVBqw9Suu/dQtkB/y0jz1+/A34VI9wiP8sdOd8BfDsift683xfW9EOspbb7BFm6UH+VslP+c8plE+cNeu07KDu5P6N8Vw+MMq2R1vPt/AuwS0QcsgbT6pbhti9fBm5vvlsoB7BPatb7H6UERXhs27AN5XN8upkHTmDkAzPjuVx0rAl5V1LmkYsp27hWpwLXNNvv51Hub/Bkyj7VuRFxI+U6zIFLXL5B2QY/SAmAF0XEbZSD3W0D3gjb9AlhmG3ULxh93dP6HisoAfCLbfaT12Ybs870rV497tNUJZozXh+iXP9zWq/r0cQRLXcS63Ep653mzN/Lmq46RMQ3KHcz7vpF5utalDsfzs/M86LcMOlHlDuE3jLM+HdT5pu7x6/K9UtzxnAJEM01X2vzXqszc8zd9SeK5oj7XZl5bZRrwn4A/FWW6w6rFhFvBy7PzNsj4hnA57Lc3GK9ntZYNWeyvgj8V2Z+rdf1aGIZ6zZqfdVp1ztNYlHupPXVYZ4+NsuF92viBko3pYPX8PWPExFfYuhF8AAXZ+Yp62Ia0npgEbBXc0R6NeX6l17ebXZtJPCPEfFOSk+V8ybbRnY8Rblr3Z3AD9Y2CI4wjfVpPXwH8JnmwGQ/5fb2owbBiJhJ2elr55SmC/z67k7gPyOin3L99HGdvGgN9xfWaFrd1nTxu5dyR8yv97YaTVBVbKM8MyhJkiRJFer53Z0kSZIkSePPMChJkiRJFTIMSpIkSVKFvIGMJEktImI15XbrrT9of0NmHruG77cX8MbMnEi/nyVJkmFQkqQ2/nod3pFzF2DbdfRekiStM4ZBSZI6FBE7UX7AfQ7lx4ZPz8xzmt/3+zjwbGAW0AccS/kh+Q8Am0bEFyg//v3pzNy1eb8FA48j4lRgX8qPWt+cmUdFxEnAKymXddwNvKXlx7ElSVorhkFJkob6fkS0dhN9EXA/cCFwdGb+NCI2BX4UEbdTwt82wL6Z2R8RJwInZubLI+IU4LDMfEMT/kayPbBrZq6MiNcBuwF7N4/fBJwNvHSdflJJUrUMg5IkDTWkm2hE7Az8FXBORAwMngnsmZlnRsTJwJubH+ZeADy8BtO9LjNXNn8fBOwN3NBMbyqw0Rq8pyRJbRkGJUnqzFTgwczcY2BARGwFPBgRL6N0H/0Y8A3gDuCoNu+xmnIWccAGg55fOmh6H8nMM5tpbQg8YS0/gyRJf+FPS0iS1JkEHomIowAi4kmUu44+EzgA+GYT3G4AXkEJcwArgenN30uA7SJiy4joA149wvS+DRwbEbObxx8AvrjuPo4kqXaGQUmSOpCZy4FDKAHtFuA7wPsz81rgM8CCiLgV+CnwS+DJzY1lrgOeEhFfy8zbgbMogfE64K4RJnk2cAlwXUTcBjwdOKYrH06SVKW+1atX97oGSZIkSdI488ygJEmSJFXIMChJkiRJFTIMSpIkSVKFDIOSJEmSVCHDoCRJkiRVyDAoSZIkSRUyDEqSJElShf4/aJA3G6+jLZcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=\"Feature\", y=\"importance\", data=df_fi)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bb59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
